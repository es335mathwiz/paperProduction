
@TechReport{RePEc:msh:ebswps:2015-10,
  author={Christoph Bergmeir and Rob J Hyndman and Bonsoo Koo},
  title={{A Note on the Validity of
      Cross-Validation for Evaluating Time Series Prediction}},
  year=2015,
  month=,
  institution={Monash University, Department of Econometrics and Business Statistics},
  type={Monash Econometrics and Business Statistics Working Papers},
  url={https://ideas.repec.org/p/msh/ebswps/2015-10.html},
  number={10/15},
  abstract={One of the most widely used standard procedures for model
    evaluation in classification and regression is K-fold
    cross-validation (CV). However, when it comes to time series forecasting,
    because of the inherent serial correlation and potential non-stationarity
    of the data, its application is not straightforward and often omitted by
    practitioners in favor of an out-of-sample (OOS) evaluation. In this paper,
    we show that the particular setup in which time series forecasting is
    usually performed using Machine Learning methods renders the use of
    standard K-fold CV possible. We present theoretical insights supporting
    our arguments. Furthermore, we present a simulation study where we show
    empirically that K-fold CV performs favourably compared to both OOS
    evaluation and other time-series-specific techniques such as
    non-dependent cross-validation.},
  keywords={cross-validation; time series; auto regression.},
  doi={},
}



@misc{rabinowicz2020crossvalidation,
      title={Cross-Validation for Correlated Data}, 
      author={Assaf Rabinowicz and Saharon Rosset},
      year={2020},
      eprint={1904.02438},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}


@article{bergmeir12,
author = {Bergmeir, Christoph and Benítez, José},
year = 2012,
month = 05,
pages = {192–213},
title = {On the use of cross-validation for time series predictor evaluation},
volume = 191,
journal = {Information Sciences},
doi = {10.1016/j.ins.2011.12.028}
}





@article{carmack09:_far_castin_cross_valid,
author = {Patrick S. Carmack and William R. Schucany and Jeffrey S. Spence and Richard F. Gunst and Qihua Lin and Robert W. Haley},
title = {Far Casting Cross-Validation},
journal = {Journal of Computational and Graphical Statistics},
volume = 18,
number = 4,
pages = {879-893},
year  = 2009,
publisher = {Taylor & Francis},
doi = {10.1198/jcgs.2009.07034},

URL = { 
        https://doi.org/10.1198/jcgs.2009.07034
    
},
eprint = { 
        https://doi.org/10.1198/jcgs.2009.07034
    
}

}



@article{carmack12:_gener,
author = { Patrick   S.   Carmack  and  Jeffrey   S.   Spence  and  William   R.   Schucany },
title = {Generalised correlated cross-validation},
journal = {Journal of Nonparametric Statistics},
volume = 24,
number = 2,
pages = {269-282},
year  = 2012,
publisher = {Taylor & Francis},
doi = {10.1080/10485252.2012.655733},

URL = { 
        https://doi.org/10.1080/10485252.2012.655733
    
},
eprint = { 
        https://doi.org/10.1080/10485252.2012.655733
    
}

}

@techreport{Schnaubelt2019comparison,
abstract = {Machine learning is increasingly applied to time series data, as it constitutes an attractive alternative to forecasts based on traditional time series models. For independent and identically distributed observations, cross-validation is the prevalent scheme for estimating out-of-sample performance in both model selection and assessment. For time series data, however, it is unclear whether forwardvalidation schemes, i.e., schemes that keep the temporal order of observations, should be preferred. In this paper, we perform a comprehensive empirical study of eight common validation schemes. We introduce a study design that perturbs global stationarity by introducing a slow evolution of the underlying data-generating process. Our results demonstrate that, even for relatively small perturbations, commonly used cross-validation schemes often yield estimates with the largest bias and variance, and forward-validation schemes yield better estimates of the out-of-sample error. We provide an interpretation of these results in terms of an additional evolution-induced bias and the sample-size dependent estimation error. Using a large-scale financial data set, we demonstrate the practical significance in a replication study of a statistical arbitrage problem. We conclude with some general guidelines on the selection of suitable validation schemes for time series data.},
address = {N\"{u}rnberg},
author = {Matthias Schnaubelt},
copyright = {http://www.econstor.eu/dspace/Nutzungsbedingungen},
keywords = {330; machine learning; model selection; model validation; time series; cross-validation},
language = {eng},
number = {11/2019},
publisher = {Friedrich-Alexander-Universit\"{a}t Erlangen-N\"{u}rnberg, Institute for Economics},
title = {A comparison of machine learning model validation schemes for non-stationary time series data},
type = {FAU Discussion Papers in Economics},
url = {http://hdl.handle.net/10419/209136},
year = {2019}
}

@article{roberts16:_cross,
author = {Roberts, David and Bahn, Volker and Ciuti, Simone and Boyce, Mark and Elith, Jane and Guillera-Arroita, Gurutzeta and Hauenstein, Severin and Lahoz-Monfort, Jose and Schröder, Boris and Thuiller, Wilfried and Warton, David and Wintle, Brendan and Hartig, Florian and Dormann, Carsten},
year = 2016,
month = 12,
title = {Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure},
volume = 40,
journal = {Ecography},
doi = {10.1111/ecog.02881}
}

@article{Cerqueira_2020,
   title={Evaluating time series forecasting models: an empirical study on performance estimation methods},
   volume={109},
   ISSN={1573-0565},
   url={http://dx.doi.org/10.1007/s10994-020-05910-7},
   DOI={10.1007/s10994-020-05910-7},
   number={11},
   journal={Machine Learning},
   publisher={Springer Science and Business Media LLC},
   author={Cerqueira, Vitor and Torgo, Luis and Mozetič, Igor},
   year={2020},
   month={Oct},
   pages={1997–2028}
}


@ARTICLE{RePEc:eee:csdana:v:76:y:2014:i:c:p:132-143,
title = {On the usefulness of cross-validation for directional forecast evaluation},
author = {Bergmeir, Christoph and Costantini, Mauro and Benítez, José M.},
year = {2014},
journal = {Computational Statistics & Data Analysis},
volume = {76},
number = {C},
pages = {132-143},
abstract = {The usefulness of a predictor evaluation framework which combines a blocked cross-validation scheme with directional accuracy measures is investigated. The advantage of using a blocked cross-validation scheme with respect to the standard out-of-sample procedure is that cross-validation yields more precise error estimates of the prediction error since it makes full use of the data. In order to quantify the gain in precision when directional accuracy measures are considered, a Monte Carlo analysis using univariate and multivariate models is provided. The experiments indicate that more precise estimates are obtained with the blocked cross-validation procedure. An application is carried out on forecasting UK interest rate for illustration purposes. The results show that in such a situation with small samples the cross-validation scheme may have considerable advantages over the standard out-of-sample evaluation procedure as it may help to overcome problems induced by the limited information the directional accuracy measures contain due to their binary nature.},
keywords = {Blocked cross-validation; Out-of-sample evaluation; Forecast directional accuracy; Monte Carlo analysis; Linear models;},
url = {https://EconPapers.repec.org/RePEc:eee:csdana:v:76:y:2014:i:c:p:132-143}
}