
%http://mathematica.stackexchange.com/questions/11350/xkcd-style-graphs
\documentclass[12pt]{article}
\input{AMArepresentationNewCmds}
\title{A New Series Representation for Time Invariant Maps that
 Arise in  Dynamic Economic Models}

%\date{\currenttime -- \today }


%\newtheorem{theorem}{Theorem}[section]

\author{Gary S. Anderson\thanks{The analysis and conclusions set forth are those of the author and do not indicate concurrence by other members of the research staff or the Board of Governors. I would like to thank Luca Guerrieri, Christopher Gust, Hess Chung, Benjamin Johannsen  and Robert Tetlow for their comments and suggestions. }}




\begin{document}
\maketitle

\begin{abstract}


 
This paper proposes a new series representation for bounded
time invariant discrete time maps.
The paper uses the representation to develop  formulae
for computing accuracy bounds for any proposed time invariant model solution.
The paper also provides an algorithm for computing
solutions for dynamic economic models.

With the series representation for time invariant maps in hand,
the paper shows how to use the solution to a deterministic problem at
time t, to improve upon a proposed solutions for
any given dynamic economic models with occasionally
binding constraints or regime switching or both.   The error bounds from the
series representation help with determining algorithmic convergence by
characterizing the potential benefits
of further solution refinement.


% In this context, it  facilitates exploiting the 
% ``law of iterated expectations'' in computing rational expectations solutions for models with occasionally binding constraints.


\end{abstract}

 \newpage
 \tableofcontents
 \newpage



\section{Introduction and Summary}





Stochastic dynamic non linear economic
models increasingly embody  occasionally binding constraints (OBC) essential
Since \cite{Christiano2000} a host of
authors have described a variety of approaches. 
\cite{holden15:_exist_dsge,guerrieri15:_occbin,benigno09,hintermaier10,brumm10,nakov08,haefke98,nakata12,gordon11,billi11,Hintermaier2010,Guerrieri2015}
This paper provides yet another.  This new series representation provides  a coherent framework for attacking a wide variety of complicated nonlinear models.
The framework provides a new way to bound the error one can expect from
employing a given proposed model solution and leads to a
algorithm with  components similar to parameterized expectations that
one can use to improve proposed solutions. The series representation makes
it possible to organize the calculation around computing a deterministic
problem at time t given a proposed solution.  The deterministic solution
can accommodate inequality constraints or alternative regimes to produce a
solution for each set of initial conditions.  One can typically arrange,
perhaps by adding auxiliary variables, to produce a ``decision rule''
that one can correctly integrate to get a deterministic conditional
expectation function that can be iterated forward and serves to
improve upon the original proposed solution.
Time invariant stochastic functions 
lead naturally to an associated family of deterministic maps
which can conveniently represented by the series representation.




\begin{figure}
  \centering
  


  \begin{gather}
    \fbox{Nonlinear Rational Expectations Model}\\ \Downarrow\\
\fbox{Bounded Time Invariant Function Solution}\\\Downarrow\\
\fbox{Series Representation}\\\Downarrow\\
\fbox{Series Approximation}
  \end{gather}
  \caption{From Models to Approximate Solutions}
  \label{fig:modelsto}
\end{figure}


This series representation for deterministic maps,
broadly applicable for nonlinear rational expectations models 
leads to a formulae for accuracy bounds for any proposed solution.
As an important component in an algorithm for
constructing approximate solutions it
facilitates exploiting recursive computation of the solutions for complicated models.
The algorithm has been implemented in
Mathematica code that can compute solutions for
nonlinear models with occasionally binding constraints and/or regime switching models.








\section{A Series Representation for A Bounded Family of Paths}
\label{sec:seri-repr-bound}

Consider a family of {\it time invariant } stochastic functions:
 \begin{gather}
   \xWarg \in{R^L}\,\text{ with }\,\infNorm{\xWarg}  \le \bar{\mathcal{X}}\,\,\forall t> 0 \label{fFamily}.
 \end{gather}
The $x_{-1}$ is an  $L$ dimensional state vector and $\epsilon$ is a $K$ dimensional ``shock'' vector that together index
individual trajectories for future state vectors.  
Each member of the family characterizes the evolution of a {\em deterministic} trajectory of values.\footnote{Subsequent sections describe how these deterministic trajectories are useful for representing a wide array stochastic model solutions.}

It will prove useful to also define a time invariant deterministic function $\XtFuncTI\equiv \expctEps{\xtFuncTI}$ and denote
\begin{gather*}
\xsubtFunc{t+k}{(x_{t-1},\epsilon_t)}\equiv\begin{cases}
\xtFunc{(x_{t-1},\epsilon_t)} &k=0\\
\XtFunc{(\xsubtFunc{t+k-1}{(x_{t-1},\epsilon_t)})} &k>0
\end{cases}
\end{gather*}

Iterating conditional expectations of stochastic functions forward will lead
us to a series representation useful for representing dynamic model solutions.
Many rational expectations models have solutions characterized by a stochastic function $\mathcal{X}(x_{t-1},\epsilon_t):\mathcal{R}^n \times \mathcal{R}^k \rightarrow \mathcal{R}^n$ $\epsilon_t \sim iid$.
Consider Iterating the function $\mathcal{X}$ forward by 
recursively applying $\XtFunc{}$ to compute a solution path
\begin{gather}
\underbrace{(x_{t-1},\epsilon_t)} 
\underbrace{{\mathcal{X}}(x_{t-1},\epsilon_t)}
\underbrace{\xsubtFunc{t+1}{(x_{t-1},\epsilon_t)}}
\underbrace{\xsubtFunc{t+2}{(x_{t-1},\epsilon_t)}}
\underbrace{\ldots}
\intertext{Now, suppose this iteration produces bounded trajectories }
\infNorm{\xsubtFunc{t+k}{(x_{t-1},\epsilon_t)}}  \le \bar{\mathcal{X}}\,\,\forall s\ge 0 \label{fFamily}.
 \end{gather}
then it will then, be possible to write down a useful 
series representation for
the function $\mathcal{X}(x_{t-1},\epsilon_t)$.
These series will be based upon
discrepancies from an ``arbitrary'' Blanchard-Kahn linear dynamic
system.\footnote{As seen below, the linearity of the saddle point model
  will not preclude applying the technique to highly non linear models.}













For any linear homogeneous 
$L$ dimensional 
deterministic 
system 
\begin{gather}
  	 H_{-1} x_{t-1} + H_0 x_t + H_1 x_{t+1}=0\label{hSystem}
\end{gather}
that produces  a unique stable solution, 
it is well known\ \citep{anderson10} that  inhomogeneous solutions 
\begin{gather}
	 H_{-1} x_{t-1} + H_0 x_t + H_1 x_{t+1}=\psi_\epsilon \epsilon +\psi_{c}
\intertext{ can be computed as}
x_t=B x_{t-1} + \phi \psi_\epsilon \epsilon + (I - F)^{-1} \phi \psi_c
\intertext{where}
\phi= (H_0 +H_1 B)^{-1}  \text{ and } \,\,F=-\phi H_1 
\end{gather}
It will be useful to collect the components of this representation for use in
subsequent sections of the paper.
Define $\linMod \equiv \linModMats$.


{\small
Now, given the trajectories \refeq{fFamily}, define 
$  z_{t}(x_{t-1},\epsilon)$ as  %\footnote{These $z$ functions will soon prove useful in an algorithm for computing unknown trajectories like \refeq{fFamily}.}:
{
  \begin{align}
  z_{t}(x_{t-1},\epsilon) \equiv& H_{-1} \mathcal{X}_{t-1}(x_{t-1},\epsilon) + \nonumber\\
& H_0 \mathcal{X}_{t}(x_{t-1},\epsilon) +  \label{defZ} \\
& H_1 \mathcal{X}_{t+1}(x_{t-1},\epsilon). \nonumber
  \end{align}
}

\begin{theorem}
	 \begin{gather}
	 \mathcal{X}_{t}(x_{t-1},\epsilon) =B x_{t-1}+ \phi \psi_\epsilon\epsilon + (I - F)^{-1} \phi \psi_c + \sum_{\sForSum=0}^\infty F^s \phi z_{t+\sForSum}(x_{t-1},\epsilon) \label{theSeries}
\intertext{and}
	 \mathcal{X}_{t+1}(x_{t-1},\epsilon) =B \mathcal{X}_{t} + \sum_{\sForSum =0}^\infty F^\sForSum \phi z_{t+\sForSum}(x_{t-1},\epsilon) + (I - F)^{-1} \phi \psi_c \,\,\,\forall t \ge  0.
	 \end{gather}
\end{theorem}
}
% \begin{proof}
%   For every bounded family of functions,
%   $\mathcal{X}_t(x_{t-1},\epsilon_t)$, \citep{anderson10}  shows that for any given $x_{t-1},\epsilon_t$ this expression must be true.
% Since the eigenvalues of F are all less than one and the $z$'s are bounded,
%  the series always converges.
% \end{proof}


	 Consequently, given a family of trajectories like those in \refeq{fFamily},
and a stable linear homogeneous system like \refeq{hSystem},
one can easily compute a series 
representation \refeq{theSeries} for any  bounded function generating a family of
trajectories.
Interestingly, the linear model, $H$, the  constant term $\psi_c$ and the
impact of the stochastic shocks $\psi_\epsilon $ can  be 
chosen rather arbitrarily -- the only constraint being the existence of a saddle-point solution or the linear system.  
The formula will provide a series  for any 
$L$ dimensional $\linMod$.
This observation will give us some confidence in the 
robustness of the algorithms described in section 
\ref{sec:unknown-solutions} for constructing series 
representations for unknown families of functions 
satisfying complicated systems of dynamic non-linear equations.



One could consider approximating $\mathcal{X}_t(x_{t-1},\epsilon)$ by 
truncating the series \ref{theSeries} at a finite number of terms.
 	 \begin{gather}
 	 \xWargK \equiv B x_{t-1}+ \phi \psi_\epsilon\epsilon + \sum_{s=0}^k F^s \phi z_{t}(x_{t-1},\epsilon) + (I - F)^{-1} \phi \psi_c \label{theTruncSeries}
 \end{gather}
We can bound the  series approximation truncation errors.
Since
    \begin{gather}
      \label{eq:1}
\sum_{s=k+1}^{\infty} F^s \phi \psi_z = (I -F)^{-1} F^{k+1}\phi \psi_z       \\
\infNorm{\xWarg-\xWargK} \le \infNorm{(I -F)^{-1} F^{k+1}\phi \psi_z} \left ( \infNorm{H_{-1} }+ \infNorm{H_{0} }+ \infNorm{H_{1} } \right )\bar{\mathcal{X}}
    \end{gather}
Note that for approximating $\xWarg$ the impact of  a given realization along the path declines for those realizations which are  more temporally distant.




\subsection{A Simple Example: An ``Almost'' Arbitrary Linear Model and an Arbitrary Family of Bounded Solution Paths}
\label{sec:almostarbitrary}


Consider the following constructed from ``almost'' arbitrary coefficients
\begin{gather}
  \begin{bmatrix}
H_{-1}&H_{0}&H_{1} 
  \end{bmatrix}=
\vcenter{\hbox{\includegraphics{refHmat.pdf}}}\intertext{with $\psi_c=\psi_\epsilon=0, \,\,  \psi_z=I$.
These coefficients are not completely arbitrary in so far as the series 
representation requires that the linear model
has a unique stable solution.}
  B=
\vcenter{\hbox{\includegraphics{refBmat.pdf}}}\\
\phi=
\vcenter{\hbox{\includegraphics{refPhimat.pdf}}}\\
F=
\vcenter{\hbox{\includegraphics{refFmat.pdf}}}
\end{gather} 



The series representation requires that the state values along the 
paths remain bounded.  For example, consider the following three
bounded families of state vector paths generated by Mathematica code.
\begin{verbatim}
genPiPath[init_?MatrixQ,eps_?MatrixQ,kk_Integer]:=
		With[{theDigits=RealDigits[Pi,10,kk][[1]]},
			 N[(Norm @ init)]/(1+N[Norm @ eps]) *theDigits]
genOscilPath[init_?MatrixQ,eps_?MatrixQ,kk_Integer]:=
		With[{theOscil=NestList[-1*#&,1,kk-1]},
			 N[(Norm @ init)]/(1+N[Norm @ eps])^2 *theOscil]
genRandomPath[init_?MatrixQ,eps_?MatrixQ,kk_Integer]:=
		Module[{},SeedRandom[Round[200*N[(Norm @ init)]+Norm[eps]]]; 
				  RandomReal[{-4,4},kk]]
\end{verbatim}


The first set of trajectories(See Figure \ref{pipath}) is a function of
the digits in the decimal representation of $\pi$.  
determined by a nonlinear function of the initial conditions and a random shock.
The second set of trajectories (See Figure \ref{oscillpath}) oscillates between two values
determined by  a nonlinear function of the initial conditions and the shock.
The third set of trajectories (See Figure \ref{pseudopath}) is a sequence of uniformly distributed random
numbers based on a seed determined by  a nonlinear function of  the initial conditions and the shock.
These examples paths were chosen to emphasize that the trajectories
 need not converge to a fixed point, and 
need not be produced by iteration of a discrete-time map.
The boundedness of the paths is a sufficient condition for the existence 
of the series representation.\footnote{Although useful in some contexts,
this paper will not investigate sufficient conditions for families of
unbounded trajectories.}


\begin{figure}
  \centering
\includegraphics[width=2in]{piPath.pdf}
  
  \caption{$\pi$ Digits Path}\label{pipath}
\end{figure}
\begin{figure}
  \centering
\includegraphics[width=2in]{oscillPath.pdf}
  
  \caption{Oscillatory Path}\label{oscillpath}
\end{figure}

\begin{figure}
  \centering
\includegraphics[width=2in]{pseudoPath.pdf}
  \caption{Uniformly Distributed Path}\label{pseudopath}
\end{figure}

\begin{figure}
  \centering
\includegraphics[width=3in]{theZs.pdf}  
  \caption{The  z's Corresponding to  $x_{-1}=(1,2,3),\epsilon=(2,1,2)$} \label{arbFig}
\end{figure}

\begin{figure}
  \centering


\includegraphics[width=3in]{arbTruncErr.pdf}  
  \caption{Error Bound Versus Actual Error} \label{figArbTrunc}

\end{figure}


Figure \ref{arbFig} shows, for a particular initial state vector and shock value,  the paths for the state vectors and the correct z's that generate the path.
One can repeat the calculations for any given initial condition to produce
a z series exactly replicating the given set of trajectories.  The family
of z functions along with equation \ref{theSeries} provide a series 
representation for the family of trajectories.  Figure \ref{figArbTrunc} shows
that the truncation error bound is a very conservative measure of the accuracy
of the truncated series.  The series requires only the first 20 terms to compute
the initial value of the state vector to machine precision. 
The series representation can compute the entire series to machine precision
if all the terms are included, but the terms for state vectors closer 
to the initial time have the most important impact.






\subsection{Example: A Simple RBC Model Example With Known Solution}
\label{sec:simple-rbc-model-2}


 {\bf RBC Model Example}
  See \cite{Maliar2005}
 \begin{gather*}
   \max\left \{  u(c_t^t) + E_t \sum_{\tau=t}^\infty \beta \delta^{\tau+1-t}u(c_{\tau+1}^t)\right \}\\
c_\tau^t + k_\tau^{t+1}=(1-d)k_\tau^{t-1} + \theta_\tau f(k_\tau^{t-1})\\
f(k_\tau^{t-1})= k_\tau^\alpha
 \end{gather*}

\begin{gather}
\frac{1}{c_t^{\eta}}=\alpha \delta k_{t}^{\alpha-1} E_t \left (\frac{\theta_{t}}{c_{t+1}^\eta} \right ) \\
c_t + k_t=\theta_{t-1}k_{t-1}^\alpha \\
 \theta_t =\theta_{t-1}^\rho e^{\epsilon_t}\label{rbcSys}
\intertext{for $\eta=1$}
\frac{1}{c_t}=\alpha \delta k_{t}^{\alpha-1} E_t \left (\frac{\theta_{t}}{c_{t+1}} \right ) \\
c_t + k_t=\theta_{t-1}k_{t-1}^\alpha \\
\theta_t =\theta_{t-1}^\rho e^{\epsilon_t}\label{rbcSys}
\intertext{and there is a closed form solution}
  k_{t}= \alpha \delta \theta_{t} k_{t-1}^\alpha.\label{soln}\\
c_t=  (1-\alpha \delta) \theta_{t} k_{t-1}^\alpha
\end{gather}
For mean zero iid $\epsilon_t$ we can easily compute a family of trajectories like \refeq{fFamily}
\begin{gather}
  \begin{bmatrix}
c_{t+s}(k_{t-1},\theta_t,\epsilon_t)\\k_{t+s}(k_{t-1},\theta_t,\epsilon_t)    \\ \theta_{t+s}(\theta_{t-1},\theta_t,\epsilon_t)    
  \end{bmatrix}
\intertext{with conditional mean converging over time to }
  \begin{bmatrix}
    c_{ss}\\k_{ss}
  \end{bmatrix}=
  \begin{bmatrix}
\nu^\alpha-\nu\\ \nu
  \end{bmatrix}\intertext{where}
\nu= \alpha ^{\frac{1}{1-\alpha }} \delta ^{\frac{1}{1-\alpha }}
\end{gather}


We can use the family of conditional expectations
along with the contrived reference model to recover an 
approximation for equation \refeq{soln} along with error bounds.
The series representation provides a weighted sum of z functions that give us
an approximation for the known solution.
\footnote{Note that the reference model is deterministic and the $z$ functions account for the stochastic nature of the model.}
% \footnote{
% We need not  make these adjustments for the steady state,
% but doing so economizes on the number of terms 
% required for a given level of approximation
% accuracy.}

Using the following parameter values

\begin{gather}
\vcenter{\hbox{\includegraphics{RBCParamSubs.pdf}}} \,\, \text{ we have } \,\,
  \begin{bmatrix}
    c_{ss}\\k_{ss} \\ \theta_{ss} \label{rbcparams}
  \end{bmatrix}=
\vcenter{\hbox{\includegraphics{RBCSSVal.pdf}}}
\end{gather}%(\footnote{{RBCParamSubs.pdf}})(\footnote{{RBCSSVal.pdf}})


\begin{figure}
  \centering
\includegraphics{simpBoundsVActual.pdf}  
  \label{rbcTrunc}
  \caption{RBC Truncation Error Bound Versus Actual}
\end{figure}
\subsection{Constructing an Approximation: Problem Restatement}
\label{sec:constr-an-appr}


To describe the algorithm we will, for the moment, omit inequality constraints
and regime switching.
We will develop an algorithm for finding solutions for models that can be written in  the form


\begin{gather}
  h_i(x_{t-1},x_{t},x_{t+1},\epsilon_t)=h^{det}_{io}(x_{t-1},x_{t},\epsilon_t)+\sum_{j=1}^{p_i} [h^{det}_{ij}(x_{t-1},x_{t},\epsilon_t)h^{nondet}_{ij}(x_{t+1})]=0
\end{gather}
This is a very broad class of models including most widely used
macroeconomics models.

For example, the Euler equations for the  neoclassical growth  model 
\label{sec:simple-rbc-model-ext} can be written as
\begin{gather}
h_{10^{det}}(\cdot)=\frac{1}{c_t},\,\,
h_{11}^{det}()=\alpha \delta k_{t}^{\alpha-1} ,\,\,
h_{11}^{nondet}(\cdot)=E_t \left (\frac{\theta_{t+1}}{c_{t+1}} \right )\\
h_{20}^{det}(\cdot)=c_t + k_t-\theta_tk_{t-1}^\alpha,\,\,
h_{21}^{det}(\cdot)=0\\
h_{30}^{det}(\cdot)=\ln \theta_t -(\rho \ln \theta_{t-1} + \epsilon_t),\,\,
h_{31}^{det}(\cdot)=0
\end{gather}
Since we will be working with models where expectations are computed at time t, $\epsilon_t$ is known.  The only stochastic components are those with time subscripts greater than $t$. Since we will need to compute 
the conditional expectation of nonlinear expressions,  
this setup will make it possible for us to use auxiliary
variables to correctly compute the required expected values.
Below, we will consider 
systems that augment these dynamic equations with additional constraints 
on the evolution of the variables.


The algorithm will construct
 a time invariant function $g^\ast$ that satisfies
\begin{gather}
  \begin{split}
h(x_{t+s-1},g^\ast(x_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(x_{t+s-1},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) \label{theProblem} \\
%m(x_{t+s-1},g^\ast(x_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(x_{t+s-1},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) \ge 0  
  \end{split}
%  \intertext{define} 
% \mathcal{G}^\ast(x_{t+s-1},\epsilon_{t+s})= \mathcal{H}[g^\ast(g^\ast(x_{t+s-1},\epsilon_{t+s}),\epsilon_{t+s+1})] \nonumber
 \end{gather}
 for all $s>0$ where $\mathcal{H}$ is an operator, 
  that maps stochastic functions of $x$ and $\epsilon$ into deterministic 
functions of $x$ alone.  In this paper we will consider two such operators:










We begin by choosing some linear model of appropriate dimension that 
has a uniquely convergent steady state.  
Although this is not necessary, it may be possible to obtain this model by
linearizing the original model around the deterministic steady state.\footnote{As noted above, one could construct a series representation using any linear
 model of appropriate dimension with a unique stable solution.  The rate of convergence and the number of terms required for a  given level of accuracy will depend upon the linear model employed.}


 \begin{gather}
 g^0(x_{t-1},\epsilon_{t})=  
B x_{t-1}+ \phi \psi_\epsilon\epsilon_{t} +
 (I - F)^{-1} \phi \psi_c\\ \label{firstIter}
z^{0}_{t+i}(x_{t-1},\epsilon_{t-1})=0 \,\, \forall i \ge 0
 \end{gather}
We are now in a position to easily compute 
 \begin{gather}
\xIter{0}{x}=\mathcal{H}^{PF}[g^{0}(x,\epsilon_{t-k+1})]=
\mathcal{H}^{RE}[g^{0}(x,\epsilon_{t-k+1})]= 
B x+  (I - F)^{-1} \phi \psi_c
 \end{gather}
\begin{gather}
\underbrace{x_{t-1},0} 
\underbrace{\xNow{0},\zNow{0}}
\underbrace{\xNowtp{0}=\xIter{0}{x_{t}},0}
\end{gather}
In other words, from time t onwards, this approximation assumes 
that our stand-in
 convergent linear model completely characterizes the solution.\footnote{
The algorithm terminates with an approximation for 
the time invariant function $g^\ast$.}  It is unlikely that $g^0(x_{t-1},\epsilon_{t})$
satisfies equation \refeq{theProblem} for arbitrary $x_{t-1}$ even for $s=0$.
We can get a pessimistic upper bound for how far we are away from the solution 
by computing the infinity norm of substituting the variables from into Equation \refeq{theProblem}.
% \footnote{The values in Table \ref{truncTab} illustrate how
%pessimistic this approximation can be, but it turns out we can expect the accur%acy of  approximate truncation errors improve as we expand the approximation series.}

Next, we compute a solution in which the nonlinear equations are satisfied at time t alone while the stand-in linear system holds sway subsequently.
Our algorithm will  compute
\begin{gather}
\underbrace{x_{t-1},0} 
\underbrace{\xNow{1},\zNow{1}}
\underbrace{\xNowtp{1}=\xIter{1}{x_{t+1}},0}
\underbrace{\xNowtp{1}=\xIter{0}{x_{t+1}},0}
\end{gather}
that satisfy the nonlinear equation system at time t.
For a given $x_{t-1}$, we substitute
\begin{gather}
x_{t-1}, \,\,
  x_t=B x_{t-1} + \phi z^1(x_{t-1},\epsilon_t) , \,\,
  x_{t+1}=B x_{t} + \phi \mathcal{Z}^1(x_t)
\end{gather}
into the non linear equation system to determine the 
$z^1(x_{t-1},\epsilon_t)$ and consequently $x_t^1(x_{t-1},\epsilon_t)$.
We then have
 \begin{gather}
 g^1(x_{t-1},\epsilon_{t})=  
B x_{t-1}+ \phi \psi_\epsilon\epsilon_{t} +
\phi \psi_\epsilon z^1(x_{t-1},\epsilon_t)+
 (I - F)^{-1} \phi \psi_c\\ \label{firstIter}
z^{1}_{t+i}(x_{t-1},\epsilon_{t-1})=0 \,\, \forall i \ge 1
 \end{gather}
Now, $g^1(x_{t-1},\epsilon_{t})$
satisfies equation \refeq{theProblem} for arbitrary $x_{t-1}$ at time $t$ with $s=0$.  However, it probably does not solve the system for $s>0$.
We can get a pessimistic upper bound for how far we are away from the solution 
by substituting the variables and computing the infinity norm for plausible values of $x_{t-1}$.
\begin{gather}
\xNow{1},\xNowtp{1},\xNowtp{1}=\xIter{1}{x_{t+1}}
\end{gather}
into Equation \refeq{theProblem}. If the accuracy of the approximation is adequate, we need not compute any further  terms in the power series.  If not,
we are now in a position to compute our choice of
$\mathcal{Z}^1(x)=\mathcal{H}^{PF}[g^{1}(x,\epsilon_{t-k+1})]$ or
$\mathcal{Z}^1(x)=\mathcal{H}^{RE}[g^{1}(x,\epsilon_{t-k+1})]$.

%  \begin{gather}
%  g^0(x_{t-1},\epsilon_{t})=  
% B x_{t-1}+ \phi \psi_\epsilon\epsilon_{t} +
%  (I - F)^{-1} \phi \psi_c\\ \label{firstIter}
% z^{0}_{t+i}(x_{t-1},\epsilon_{t-1})=0 \,\, \forall i \ge 0
%  \end{gather}
%  \begin{gather}
%  g^0(x_{t-1},\epsilon_{t})=  
% B x_{t-1}+ \phi \psi_\epsilon\epsilon_{t} +
%  (I - F)^{-1} \phi \psi_c\\ \label{firstIter}
% z^{0}_{t+i}(x_{t-1},\epsilon_{t-1})=0 \,\, \forall i \ge 0
%  \end{gather}

Using these functions we can then compute a solution for a model whose trajectories satisfy equation system \refeq{rbcSys}
for two time periods and satisfy equation \refeq{rbcLinSys} subsequently.

\begin{gather}
\underbrace{x_{t-1},0}
\underbrace{\xNow{2},\zNow{2}} 
\underbrace{\xNowtp{2}=\XNow{2}{t}{t},\ZNow{2}{1}{t}}
\underbrace{\XNow{1}{t+1}{t},0}\underbrace{\XNow{0}{t+2}{t+1},0}    \intertext{where we have solved for $\xNow{2}$ and $\zNow{2}$ to satisfy the  equation system \refeq{theProblem}.}
\xNowtp{2}=\XNow{1}{t}{t}
\end{gather}

\begin{gather}
  \label{eq:1}
  x_t=B x_{t-1} + \phi z^2(x_{t-1},\epsilon) + F \phi \mathcal{Z}^1(x_t)\\
  x_{t+1}=B x_{t} + \phi \mathcal{Z}^1(x_t)+
 (I - F)^{-1} \phi \psi_c\\
  x_{t+2}=B x_{t+1} + (I - F)^{-1} \phi \psi_c\\
  x_{t+3}=B x_{t+2} + (I - F)^{-1} \phi \psi_c
\end{gather}

The next iteration highlights an aspect of the algorithmic step which allows us
to continue to exploit the series representation.

{\small
\begin{gather}
\underbrace{x_{t-1},0}
\underbrace{\xNow{3},\zNow{3}} 
\underbrace{\xNowtp{3}=\XNow{3}{t}{t},\ZNow{3}{1}{t}} 
\underbrace{\XNow{2}{t+1}{t},\ZNow{2}{2}{t+1}} 
\underbrace{\XNow{1}{t+3}{t+2},0}
\underbrace{\XNow{0}{t+4}{t+3},0}
\end{gather}
}

\begin{gather}
  \label{eq:1}
  x_t=B x_{t-1} + \phi z^3(x_{t-1},\epsilon) + F \phi \mathcal{Z}^2(x_t)+ F^2 \phi \mathcal{Z}^1(x_t)+
 (I - F)^{-1} \phi \psi_c\\
  x_{t+1}=B x_{t} + \phi \mathcal{Z}^1(x_t)+ F^2 \phi \mathcal{Z}^1(x_t)+
 (I - F)^{-1} \phi \psi_c\\
  x_{t+2}=B x_{t+1} + (I - F)^{-1} \phi \psi_c\\
  x_{t+3}=B x_{t+2} + (I - F)^{-1} \phi \psi_c\\
  x_{t+4}=B x_{t+2} + (I - F)^{-1} \phi \psi_c
\end{gather}



In the general iteration step we will have
\begin{gather}
  \label{eq:1}
  x_t=B x_{t-1}  \phi \psi_\epsilon \epsilon_t + (I - F)^{-1} \phi \psi_c +
\sum_{s=0}^{k} F^s \phi \mathcal{Z}^{k-s}(x_{t+s}^{k+1})\\
  x_{t+s}^{k+1}=\Pi_{s=0}^k \xIter{s}{ x_{t}^{k+1}}
\end{gather}



Needs generalization of ``chunk'' $\frac{1}{c_t}\rightarrow \left (\frac{\theta_{t+1}}{c_{t+1}^\eta} \right )$

We construct our stand-in model by augmenting the model with the equation
\begin{gather}
  \rcpC_t=\frac{1}{c_t}
\end{gather}
substituting $\rcpC_{t+1}$ for $\frac{1}{c_{t+1}}$ in the first equation and 
 linearizing the RBC model about the ergodic mean
given in \refeq{rbcparams}
{\small
\begin{gather}
  \begin{bmatrix}
H_{-1}&H_{0}&H_{1} 
  \end{bmatrix}=\\
\vcenter{\hbox{\includegraphics{RBCHmatSymb.pdf}}} \label{rbcLinSys}
\intertext{with}
\psi_\epsilon=
\begin{bmatrix}
  0\\0\\1\\0
\end{bmatrix}, \psi_z=I
\end{gather}%(\footnote{generated by AMAPaperCalcs.mth {RBCHmatSymb.pdf}})
}
These coefficients  produce a unique stable linear solution.

\begin{gather}
  B=
\vcenter{\hbox{\includegraphics{RBCBmatSymb.pdf}}},
\phi=
\vcenter{\hbox{\includegraphics{RBCPhimatSymb.pdf}}}\\
F=
\vcenter{\hbox{\includegraphics{RBCFmatSymb.pdf}}}\\
\psi_c=
\vcenter{\hbox{\includegraphics{RBCHSum.pdf}}}
\vcenter{\hbox{\includegraphics{RBCSS.pdf}}}=\vcenter{\hbox{\includegraphics{RBCPsissSymb.pdf}}}
\end{gather}%(\footnote{generated by AMAPaperCalcs.mth {RBCBmatSymb.pdf}})(\footnote{generated by AMAPaperCalcs.mth {RBCPhimatSymb.pdf}})(\footnote{generated by AMAPaperCalcs.mth {RBCFmatSymb.pdf}})(\footnote{generated by AMAPaperCalcs.mth {RBCHSum.pdf}})(\footnote{generated by AMAPaperCalcs.mth {RBCSS.pdf}})

Applying the formula \refeq{firstIter} produces:

{\tiny
\begin{gather}
  \begin{bmatrix}
c_t\\k_t\\ \rcpC_t\\\theta_t
  \end{bmatrix}=%paperCalcsRBCExample xt00
   \left(
   \begin{array}{c}
 0.359845 \epsilon _t+0.692632 k_{t-1}+0.341853 \theta _{t-1}-0.0442851
   \text{z1}_{t-1}+0.658 \text{z2}_{t-1}+0.359845 \text{z3}_{t-1}-0.111552 \\
 0.187032 \epsilon _t+0.36 k_{t-1}+0.17768 \theta _{t-1}+0.0442851
   \text{z1}_{t-1}+0.342 \text{z2}_{t-1}+0.187032 \text{z3}_{t-1}-0.0579799 \\
 -5.34898 k_{t-1}+0.342 \text{z1}_{t-1}-5.08153
   \text{z2}_{t-1}+\text{z4}_{t-1}+3.7794 \\
 \epsilon _t+0.95 \theta _{t-1}+\text{z3}_{t-1}+0.05 \\
   \end{array}
   \right)
\end{gather}
}

and 


{\tiny
%xt01=Private`computeNextXt[{Private`bmat,Private`phimat,Private`fmat,Private`psieps,Private`psic,Private`psiz},solnFunc00PF[[3+Range[3]]],{{cc},{kk},{tt}},{1}]//N//Expand//Simplify
\begin{gather}
  \begin{bmatrix}
c_{t+1}\\k_{t+1}\\ \rcpC_{t+1}\\\theta_{t+1}
  \end{bmatrix}=%paperCalcsRBCExample xt00
  \left(
   \begin{array}{c}
 0.471397 \epsilon _t+0.249347 k_{t-1}+0.447827 \theta _{t-1}+0.0306732
   \text{z1}_{t-1}+0.23688 \text{z2}_{t-1}+0.471397 \text{z3}_{t-1}-0.134618 \\
 0.245012 \epsilon_t+0.1296 k_{t-1}+0.232761 \theta _{t-1}+0.0159426
   \text{z1}_{t-1}+0.12312 \text{z2}_{t-1}+0.245012 \text{z3}_{t-1}-0.0699687 \\
 -1.00043 \epsilon _t-1.92563 k_{t-1}-0.950409 \theta _{t-1}-0.23688
   \text{z1}_{t-1}-1.82935 \text{z2}_{t-1}-1.00043 \text{z3}_{t-1}+4.08954 \\
 0.95 \epsilon _t+0.9025 \theta _{t-1}+0.95 \text{z3}_{t-1}+0.0975 \\
   \end{array}
   \right)
\end{gather}}

Substituting  these expressions into equation \refeq{rbcSys} produces
a deterministic system such that, given specific values for 
$(x_{t-1},\epsilon_{t})=(c_{t-1}, k_{t-1},\rcpC_{t-1}, \theta_{t-1}, \epsilon_t)$, we can solve for $z_{1t}(x_{t-1},\epsilon_{t})$, $z_{2t}(x_{t-1},\epsilon_{t})$, $z_{2t}(x_{t-1},\epsilon_{t})$, and $z_{4t}(x_{t-1},\epsilon_{t})$  completely determining
$c_{t}(x_{t-1},\epsilon_{t})$, $k_{t}(x_{t-1},\epsilon_{t})$, $\rcpC_{t}(x_{t-1},\epsilon_{t})$  and $\theta_{t}(x_{t-1},\epsilon_{t})$.\footnote{In this example, the lagged value,  $c_{t-1}$ does not appear in the equation system and consequently plays no role in determining the solution.}  In effect we have 
computed a solution for a model whose trajectories satisfy equation system \refeq{rbcSys}
for one time period and satisfy equation \refeq{rbcLinSys} subsequently.
% As can
% be seen in the top panel of Figure \ref{fig:cfuncfirst}, 
% imposing the constraint for even a single period captures much of the non linearity, but the bottom panel shows that the solution is 
% still significantly far away from the exact solution.


% Number of function evaluations and time.

% fixed point not necessary.

% find root must use genxz func
% takes time to construct function for findroot  called twice by fixed point, but solution guaranteed on second call.

% %\includegraphics[height=8.0in]{conExpPathsNote.pdf}(\footnote{{conExpPathsNote.pdf}})



% Took 0.01 seconds while profiling.  Findroot called the xz func about 30 times.
% \begin{figure}
%   \centering
% %\includegraphics{cFuncExt00Lin.pdf}(\footnote{{cFunc00Lin.pdf}})
%   \caption{Solution for c imposing non linear model constraints for a single period}
% %\includegraphics{cFuncExt00Exact.pdf}(\footnote{{cFunc00Exact.pdf}})
%   \caption{Solution for c imposing non linear model constraints for a single period}
%   \label{fig:cfuncfirst}
% \end{figure}

We are now in a position to compute
$\mathcal{H}^{PF}[g^{0}(x,\epsilon_{t-k+1})]$ or
$\mathcal{H}^{RE}[g^{0}(x,\epsilon_{t-k+1})]$.
Using these functions we can then compute a solution for a model whose trajectories satisfy equation system \refeq{rbcSys}
for two time periods and satisfy equation \refeq{rbcLinSys} subsequently.
\begin{gather}
  \label{eq:1}
  x_t=B x_{t-1} + \phi z_0(x_{t-1},\epsilon) + F \phi \mathcal{Z}^1(x_t)\\
  x_{t+1}=B x_{t} + \phi \mathcal{Z}^1(x_t)
\end{gather}
% {\tiny

% \begin{gather}%paperCalcsRBCExample.mth xt01
%   \label{eq:2}
%    \left(
%    \begin{array}{c}
%  0.359845 \epsilon _t+0.692632 k_{t-1}+0.341853 \theta _{t-1}-0.0442851
%    \text{z1}_{t-1}-0.0442851 \text{Z1}_{t-1}+0.658 \text{z2}_{t-1}+0.359845
%    \text{z3}_{t-1}+0.225036 \text{Z3}_{t-1}-0.0151455 \text{Z4}_{t-1}-0.111552 \\
%  0.187032 \epsilon _t+0.36 k_{t-1}+0.17768 \theta _{t-1}+0.0442851
%    \text{z1}_{t-1}+0.0442851 \text{Z1}_{t-1}+0.342 \text{z2}_{t-1}+0.187032
%    \text{z3}_{t-1}-0.225036 \text{Z3}_{t-1}+0.0151455 \text{Z4}_{t-1}-0.0579799 \\
%  -5.34898 k_{t-1}+0.342 \text{z1}_{t-1}+0.342 \text{Z1}_{t-1}-5.08153
%    \text{z2}_{t-1}-1.73788 \text{Z3}_{t-1}+\text{z4}_{t-1}+0.116964
%    \text{Z4}_{t-1}+3.7794 \\
%  \epsilon _t+0.95 \theta _{t-1}+\text{z3}_{t-1}+0.05 \\
%    \end{array}
%    \right)
% \end{gather}
% }

% {\tiny
%   \begin{gather}
%     \label{eq:3}
%        \left(
%    \begin{array}{c}
%  0.471397 \epsilon _t+0.249347 k_{t-1}+0.447827 \theta _{t-1}+0.0306732
%    \text{z1}_{t-1}-0.0578969 \text{Z1}_{t-1}+0.23688 \text{z2}_{t-1}+0.658
%    \text{Z2}_{t-1}+0.471397 \text{z3}_{t-1}+0.429014 \text{Z3}_{t-1}-0.00465525
%    \text{Z4}_{t-1}-0.134618 \\
%  0.245012 \epsilon _t+0.1296 k_{t-1}+0.232761 \theta _{t-1}+0.0159426
%    \text{z1}_{t-1}+0.104513 \text{Z1}_{t-1}+0.12312 \text{z2}_{t-1}+0.342
%    \text{Z2}_{t-1}+0.245012 \text{z3}_{t-1}-0.119017 \text{Z3}_{t-1}+0.0205979
%    \text{Z4}_{t-1}-0.0699687 \\
%  -1.00043 \epsilon _t-1.92563 k_{t-1}-0.950409 \theta _{t-1}-0.23688
%    \text{z1}_{t-1}+0.44712 \text{Z1}_{t-1}-1.82935 \text{z2}_{t-1}-5.08153
%    \text{Z2}_{t-1}-1.00043 \text{z3}_{t-1}-0.534171 \text{Z3}_{t-1}+1.03595
%    \text{Z4}_{t-1}+4.08954 \\
%  0.95 \epsilon _t+0.9025 \theta _{t-1}+0.95 \text{z3}_{t-1}+\text{Z3}_{t-1}+0.0975 \\
%    \end{array}
%    \right)
%   \end{gather}
% }





\begin{figure}
  \centering
%\includegraphics{cFuncTwoPerErr.pdf}(\footnote{{cFuncTwoPerErr.pdf}})
 \caption{Solution for c imposing non linear model constraints for two periods}
%\includegraphics{cFuncThreePerErr.pdf}(\footnote{{cFuncThreePerErr.pdf}})
  \caption{Solution for c imposing non linear model constraints for three periods}
  \label{fig:cfuncsecond}
\end{figure}

  {Discovering Unknown Solutions}

A, conceptually, very simple solution strategy:  

  \begin{enumerate}
  \item Begin with some convergent linear model, $\linMod$, of appropriate dimension.
  \item Compute solutions honoring the model equations for time t, 
but that assume the trajectories subsequently 
evolve according to the convergent 
linear model, $\linMod$.
  \item Given solutions valid for time $t$ to $t+k$, extend the solutions to be valid for time $t$ to $t+k+1$ \label{stepNo}
\item Repeat step \ref{stepNo} unless truncation formulas indicate the solution is sufficiently accurate
  \end{enumerate}






  {Algorithm based on basic properties of deterministic maps.}
  \begin{itemize}
  \item     The $\epsilon$'s  play two distinct roles in the algorithm.
To see the two roles, consider a family of stochastic functions 
$\{\stochF{T},\ldots,\stochF{0}\}$ with 
$\stochF{k}(x,\epsilon_t): {\mathcal{R}}^{L+1} \rightarrow \mathcal{R}^L$ 
    \begin{enumerate}
\item I assume  $\epsilon_t \sim $ iid. Knowing the distribution 
of the $\epsilon_t$ makes it possible to compute 
a corresponding family of deterministic functions $\detF{k}(x)=E( \stochF{k}(x,\epsilon_t)|x) $
    \item I assume that at some initial time, say t=0, a particular 
 $\epsilon_0$ draw 
along with an $x_{-1}$, determines a unique $x_0=\stochF{T}\initXE$.
Subsequently, $x_{t}=\detF{{T-t}}(x_{t-1})\,\, \forall t>0$
    \end{enumerate}
 \item The series representation requires a unique trajectory beginning with $x_0=\stochF{T}\initXE$ and 
evolving forward from any $x_0$ given by, a potentially time varying deterministic map,  $x_t=\detF{T-t}(x_{t-1})\,\, \forall t>0$. 
  \item The algorithm for discovering unknown solutions does not rely on time invariance.
  \end{itemize}
    






  {Recursive updating}
{\small
  \begin{itemize}
  \item Given a linear reference model,$\linModMats$,  any bounded 
sequence of deterministic maps $\{\detF{T},\ldots,\detF{0}\}, \,\, T>0$ generates 
a series representation
  \begin{gather}
     \label{eq:2}
	 \mathcal{X}_{t}(x_{t-1}) =B x_{t-1}+  (I - F)^{-1} \phi \psi_c +\\ \sum_{\sForSum=0}^{T-1} F^s \phi z_{T-\sForSum}(x_{t-1}) \intertext{it is straightforward to 
update to a new series representation for the map trajectories resulting from prepending an additional deterministic map to the sequence $\detF{T+1},\ldots,\detF{0}\}$}
	 \mathcal{X}_{t}(x_{t-1}) =B x_{t-1}+  (I - F)^{-1} \phi \psi_c +\\ 
\phi z_{T+1}(x_{t-1}) + \sum_{\sForSum=1}^{T} F^s \phi z_{T+1-\sForSum}(x_{t-1}) 
  \end{gather}
\item 
  \end{itemize}
}



%\footnote{We set $\psi_c=0$  without loss of generality 
%in the expressions that follow merely to save on notation.}


{The model of interest and a linear reference model}
\begin{itemize}
\item The target model is of the form
\begin{gather}
\nlEqnLHS{x_{t-1}}{x_t}{x_{t+1}}{t}=\\
\nlEqn{x_{t-1}}{x_t}{x_{t+1}}{t}=0\\ \label{refMod}
 (L \times 1) +  (L \times L ) \cdot (L \times 1)\\
\nlEqnSel{x_{t-1}}{x_t}{x_{t+1}}{t}\\ 
\end{gather}



\item The algorithm constructs a sequence of stochastic 
functions 
  \begin{gather}
	 \stochF{k}\initXE =B x_{t-1}+ (I - F)^{-1} \phi \psi_c+  \phi \psi_\epsilon\epsilon_0  +\\ \phi z^{\{k\}}\initXE+ \sum_{\sForSum=1}^{k-1} F^s \phi z^{\{k-\nu\}}_{\sForSum}\initXE 
\label{theSeries}
  \end{gather}

\item One can show that the algorithm begins with solutions satisfying 
the linear reference model $\linModMats$ and
constructs a sequence of functions
 honoring the target model equations for successively 
longer solution horizons.
  \end{itemize}




  {Correctly Computing Expectations of Nonlinear Functions}

  \begin{itemize}
\item Auxiliary equations for non linear ``chunks'' provide mechanism for characterizing  nonlinear expectations in the future
  \item Formula maps future equation errors  to current time changes in model
variables.
\item  $\epsilon_t$ is known so that,
given a function characterizing future expectation,  model requires
a deterministic solution at time $t$
\item The formula is linear in the potentially nonlinear $z$ functions
  \end{itemize}




{Early iterations}
{\small
  \begin{itemize}
  \item $k=0$: Completely ignore the target model
  \begin{gather}
z^{\itSup{0}}\initXE=0 \intertext{ so that}
\stochF{0}\initXE=B x_{-1} + (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0  \intertext{initialize the sequence of deterministic maps with }
\{\detF{0}\initX=B x \}
  \end{gather}
  \item $k=1$: Employ the target model for one period. Use
  \begin{gather}
x_0\initXE=B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + \phi z^{\itSup{1}}\initXE\\
E(x_1\initXE)=\detF{0}(x_0\initXE) \intertext{in the deterministic equation 
\refeq{refMod} to determine $z^{\itSup{1}}\initXE$ so}
\stochF{1}\initXE = B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + 
\phi z^{\itSup{1}}\initXE \intertext{%Define $Z^{\itSup{1}}(x)\equiv E \left [ z^{\itSup{1}}\initXEN | x \right ]$ and 
 augment the sequence}
\{\detF{1}\initX=B x  + \phi Z^{\itSup{1}}(x),\detF{0}\}
  \end{gather}
  \end{itemize}
}



{Early iterations}
{\small
  \begin{itemize}
  \item $k=2$: Employ the target model for two periods. Use
  \begin{gather}
x_0\initXE=B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 +\\ \phi z^{\itSup{2}}\initXE + F \phi Z^{\itSup{1}}(x_0\initXE)\\
E(x_1\initXE)=\detF{1}(x_0\initXE) \intertext{in the deterministic equation 
\refeq{refMod} to determine $z^{\itSup{2}}\initXE$}
\stochF{2}\initXE = B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 +\\ \phi z^{\itSup{2}}\initXE + F \phi Z^{\itSup{1}}(x_0\initXE)\intertext{
Define $Z^{\itSup{2}}(x)\equiv 
E \left [ z^{\itSup{2}}\initXEN | x \right ]$}
\{\detF{2}\initX=B x  + \phi  Z^{\itSup{2}}(x) + F \phi Z^{\itSup{1}}(x_0\initXE),
\detF{1}\initX,\detF{0}\initX\}
  \end{gather}
  \end{itemize}
}




{Early iterations}
{\small
  \begin{itemize}
  \item $k=3$: Employ the target model for two periods. Use
  \begin{gather}
x_0\initXE=B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + \phi z^{\itSup{3}}\initXE +\\ F \phi Z^{\itSup{2}}(x_0\initXE) + F^2 \phi Z^{\itSup{1}}(\detF{2}(x_0\initXE))\\
E(x_1\initXE)=\detF{2}(x_0\initXE) \intertext{in the deterministic equation 
\refeq{refMod} to determine $z^{\itSup{3}}\initXE$}
\stochF{3}\initXE = B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + \phi z^{\itSup{3}}\initXE + \\F \phi Z^{\itSup{2}}(x_0\initXE) +F^2 \phi Z^{\itSup{1}}(\detF{2}(x_0\initXE))\intertext{
Define $Z^{\itSup{3}}(x)\equiv 
E \left [ z^{\itSup{3}}\initXEN | x \right ]$}
\detF{2}\initX=B x  + \phi  Z^{\itSup{3}}(x) + 
F \phi Z^{\itSup{2}}(x_0\initXE) + \\F^2 \phi Z^{\itSup{1}}(\detF{1}(x_0\initXE))
  \end{gather}
  \end{itemize}
}



{General iterations}
{\small
  \begin{itemize}
  \item $k=K+1$: Employ the target model for $K+1$ periods. Use
  \begin{gather}
x_0\initXE=B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + \phi z^{\itSup{K+1}}\initXE +\\ \sum_\sForSum^K F^\nu \phi Z^{\itSup{K+1-s}}\detComp{x_0\initXE} \\
E(x_1\initXE)=\detF{K}(x_0\initXE) \intertext{in the deterministic equation 
\refeq{refMod} to determine $z^{\itSup{K+1}}\initXE$}
\stochF{K+1}\initXE = B x_{-1}+ (I - F)^{-1} \phi \psi_c +\phi \psi_\epsilon \epsilon_0 + \phi z^{\itSup{K+1}}\initXE + \\
\sum_\sForSum^K F^\nu \phi Z^{\itSup{K+1-s}}\detComp{x_0\initXE} 
  \end{gather}
  \end{itemize}
}









  {The RBC Model ($\eta=1$): Recovering a Known Solution}
  \begin{itemize}
  \item Compute $\linMod$ for RBC Model $\eta=1,\rcpC_t=\frac{1}{c_t}$
  \end{itemize}

Applying formula \refeq{theSeries} produces:

{\tiny
\begin{gather}
  \begin{bmatrix}
c_t\\k_t\\ \rcpC_t\\\theta_t
  \end{bmatrix}=\\%paperCalcsRBCExample xt00
   \left(
   \begin{array}{c}
 0.359845 \epsilon _t+0.692632 k_{t-1}+0.341853 \theta _{t-1}-0.0442851
   \text{z1}_{t-1}+0.658 \text{z2}_{t-1}+0.359845 \text{z3}_{t-1}-0.111552 \\
 0.187032 \epsilon _t+0.36 k_{t-1}+0.17768 \theta _{t-1}+0.0442851
   \text{z1}_{t-1}+0.342 \text{z2}_{t-1}+0.187032 \text{z3}_{t-1}-0.0579799 \\
 -5.34898 k_{t-1}+0.342 \text{z1}_{t-1}-5.08153
   \text{z2}_{t-1}+\text{z4}_{t-1}+3.7794 \\
 \epsilon _t+0.95 \theta _{t-1}+\text{z3}_{t-1}+0.05 \\
   \end{array}
   \right)
\end{gather}
}

and 


{\tiny
%xt01=Private`computeNextXt[{Private`bmat,Private`phimat,Private`fmat,Private`psieps,Private`psic,Private`psiz},solnFunc00PF[[3+Range[3]]],{{cc},{kk},{tt}},{1}]//N//Expand//Simplify
\begin{gather}
  \begin{bmatrix}
c_{t+1}\\k_{t+1}\\ \rcpC_{t+1}\\\theta_{t+1}
  \end{bmatrix}=\\%paperCalcsRBCExample xt00
  \left(
   \begin{array}{c}
 0.471397 \epsilon _t+0.249347 k_{t-1}+0.447827 \theta _{t-1}+0.0306732
   \text{z1}_{t-1}+0.23688 \text{z2}_{t-1}+0.471397 \text{z3}_{t-1}-0.134618 \\
 0.245012 \epsilon_t+0.1296 k_{t-1}+0.232761 \theta _{t-1}+0.0159426
   \text{z1}_{t-1}+0.12312 \text{z2}_{t-1}+0.245012 \text{z3}_{t-1}-0.0699687 \\
 -1.00043 \epsilon _t-1.92563 k_{t-1}-0.950409 \theta _{t-1}-0.23688
   \text{z1}_{t-1}-1.82935 \text{z2}_{t-1}-1.00043 \text{z3}_{t-1}+4.08954 \\
 0.95 \epsilon _t+0.9025 \theta _{t-1}+0.95 \text{z3}_{t-1}+0.0975 \\
   \end{array}
   \right)
\end{gather}}






%   {Solution Graphs}
  

% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/exact.pdf}
% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/first.pdf}
% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/second.pdf}
% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/third.pdf}
% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/fourth.pdf}
% \includegraphics[width=2.4in]{../../../ProjectionMethodTools/ProjectionMethodToolsJava/code/fifth.pdf}





  {Begin by Solving a Deterministic System at time $t$}
{\small

  \begin{itemize}
  \item For any given $\left (  \begin{bmatrix}
c_{t-1}\\k_{t-1}\\ \rcpC_{t-1}\\\theta_{t-1}
  \end{bmatrix}, \epsilon_t \right )=\tArg$ 
compute
  \begin{gather}
    \label{eq:3}
    x_t^1\tArg=B x_{t-1} + \phi \psi_e\epsilon_t + \phi z^1_t\tArg\\
    E_t(x^1_{t+1}\tArg)=B x^1_{t}\tArg
  \end{gather}
\item The model equations provide a deterministic system  for computing $  z^1_t=\begin{bmatrix}
    z^1_{1t}\tArg\\
    z^1_{2t}\tArg\\
    z^1_{3t}\tArg\\
    z^1_{4t}\tArg
  \end{bmatrix}$.
\item The solution satisfies the nonlinear model equations for one 
period and the stand-in linear model for subsequent periods.
\item Assess accuracy
  \end{itemize}
}




%   {Assess One Period Solution Accuracy}
%   \begin{itemize}
%   \item Show graphs of solution
%   \item Show graphs of error
%   \item Report accuracy assessment bounds
%   \end{itemize}



  {Nonlinear 2 Periods: Solve time $t$ Deterministic
    System }
{\small
  \begin{itemize}
  \item Compute $Z^1(x)= E_t(z^1_t(x,\epsilon_t))$
  \item For any given $\tArg$ 
compute
{\small
  \begin{gather}
    x_t^2\tArg=B x_{t-1} + \phi \psi_e\epsilon_t + \phi z^2_t\tArg + F \phi Z^1(x^2_t) \label{bothS}\\
    E_t(x^2_{t+1}\tArg)=B x^2_{t}\tArg+ \phi Z^1(x^2_t)
  \end{gather}
}
\item The model equations provide a deterministic system  for computing $  z^2_t=\begin{bmatrix}
    z^2_{1t}\tArg\\
    z^2_{2t}\tArg\\
    z^2_{3t}\tArg\\
    z^2_{4t}\tArg
  \end{bmatrix}$.
\item The solution satisfies the nonlinear model equations for two 
period and the stand-in linear model for subsequent periods.
\item unlike the first step, $x^2_t$ appears on both sides of equation \refeq{bothS}
\item  surprisingly, a simple fixed point iteration solves the nonlinear system
\item Assess accuracy
  \end{itemize}
}



%   {Assess 2 Period Solution Accuracy}
%   \begin{itemize}
%   \item Show graphs of solution
%   \item Show graphs of error
%   \item Report accuracy assessment bounds
%   \end{itemize}








\subsubsection{Approximating the Known Solution: $U(c) = Log(c)$ }
\label{sec:recov-known-solut}

\subsubsection{Approximating an Unknown Solution: $U(c) \ne Log(c)$ }
\label{sec:unknown-solutions}

\subsubsection{Occasionally Binding Constraints}
\label{sec:obc-solut}

The algorithm we have described,
uses a proposed deterministic map
characterizing the evolution of expected values for
the dynamic system going forward. It then solves
a deterministic problem at time t to improve the proposed solution.
There is nothing in the algorithm that precludes accommodating  inequality
constraints.\footnote{See section \ref{sec:regime-switch-model} characterizing
  models with regime switching.}

\begin{gather}
  h_i(x_{t-1},x_{t},x_{t+1},\epsilon_t)=h^{det}_{io}(x_{t-1},x_{t},\epsilon_t)+\sum_{j=1}^{p_i} [h^{det}_{ij}(x_{t-1},x_{t},\epsilon_t)h^{nondet}_{ij}(x_{t+1})]=0
\end{gather}

  {Assessing Rational Expectations Solution Accuracy}

The $m$ function codifies changes in model equations due to
inequality constraints or regime switching.$(\varpi \in \{1,\ldots,n\})$
we are  interested in finding a time invariant function $g^\ast$ that satisfies
 \begin{gather}
   \begin{split}
 h_{\varpi}(x_{t+s-1},g^\ast(x_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(x_{t+s-1},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) \label{theProblem} \\
\varpi= m(x_{t+s-1},g^\ast(x_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(x_{t+s-},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) 
   \end{split}\intertext{ for all $s>0$ where $\mathcal{H}$ is an operator,    that maps stochastic to deterministic functions}
  \end{gather}


For example, the Euler equations for the  neoclassical growth  model with
irreversible investment
\label{sec:simple-rbc-model-ext} can be written as
\begin{gather}
h_{10^{det}}(\cdot)=\frac{1}{c_t},\,\,
h_{11}^{det}()=\alpha \delta k_{t}^{\alpha-1} ,\,\,
h_{11}^{nondet}(\cdot)=E_t \left (\frac{\theta_{t+1}}{c_{t+1}} \right )\\
h_{20}^{det}(\cdot)=c_t + k_t-\theta_tk_{t-1}^\alpha,\,\,
h_{21}^{det}(\cdot)=0\\
h_{30}^{det}(\cdot)=\ln \theta_t -(\rho \ln \theta_{t-1} + \epsilon_t),\,\,
h_{31}^{det}(\cdot)=0\\
(k_t>0\land\theta_t>0\land c_t>0) \land
( (I_t>\gamma I^\ast \land \lambda_t>0)\lor (I_t=\gamma I^\ast \land \lambda_t\ge0))
\end{gather}
Since we will be working with models where expectations are computed at time t, $\epsilon_t$ is known.  Once again, the only stochastic components are those with time subscripts greater than t.

\subsubsection{A Regime Switching Version}
\label{sec:regime-switch-model}

For example,
consider  the Barthelemy and Marx  Model 2: Regime Switching\cite{marxbarthelemy2012}


\cite{troy2007}
\begin{gather}
  \label{eq:4}
  i_t =E_t \pi_{t+1} + r_t\\
r_t= \rho r_{t-1} +u_t\\
i_t=\alpha_{s_t} \pi_t
\end{gather}

Bounded solutions if and only if all eigenvalues of 
\begin{gather}
  \label{eq:5}
  \begin{bmatrix}
    \frac{1}{|a_1|}&0\\
0&    \frac{1}{|a_2|}
  \end{bmatrix}
  \begin{bmatrix}
    p_{11}&p_{12}\\p_{21}&p_{22}
  \end{bmatrix}
\end{gather}
 are inside unit circle




  {Assessing Accuracy}
{\small

  \begin{itemize}
  \item As with series approximation,
 construct a family of bounded trajectories and compute
$  z_{t+s}(x_{t-1},\epsilon_t)$ as  %\footnote{These $z$ functions will soon prove useful in an algorithm for computing unknown trajectories like \refeq{fFamily}.}:
{
\begin{gather}
  z_{t+s}(x_{t-1},\epsilon_t) \equiv\\
   \begin{split}
 h_{\varpi}(\mathcal{X}_{t+s-1},g^\ast(\mathcal{X}_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(\mathcal{X}_{t+s-1},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) \label{theProblem} \\
\varpi= m(\mathcal{X}_{t+s-1},g^\ast(\mathcal{X}_{t+s-1},\epsilon_{t+s}),\mathcal{H}[g^\ast(g^\ast(\mathcal{X}_{t+s-},\epsilon_{t+s}),\epsilon_{t+s+1})],\epsilon_{t+s}) 
   \end{split}
  \end{gather}
}
\item The formula \refeq{theSeries} provides information about how much $x_{t}$ would need
to change in order for the trajectory to honor the constraints along the path
\item An exact solution should produce zero for all the $z$ functions
\item One can use a truncated series to carry out the approximation for changes in $x_t$
\item Useful to have measures of accuracy that don't rely upon knowing the solution beforehand
\item can adopt Judd approach for loss function for characterizing importance of errors
  \end{itemize}
}


  {Barthelemy and Marx  Model 2: Regime Switching
\cite{marxbarthelemy2012}}


\cite{troy2007}
\begin{gather}
  \label{eq:4}
  i_t =E_t \pi_{t+1} + r_t\\
r_t= \rho r_{t-1} +u_t\\
i_t=\alpha_{s_t} \pi_t
\end{gather}

Bounded solutions if and only if all eigenvalues of 
\begin{gather}
  \label{eq:5}
  \begin{bmatrix}
    \frac{1}{|a_1|}&0\\
0&    \frac{1}{|a_2|}
  \end{bmatrix}
  \begin{bmatrix}
    p_{11}&p_{12}\\p_{21}&p_{22}
  \end{bmatrix}
\end{gather}
 are inside unit circle





% \begin{itemize}
% \item do compositions in place instead of stacking
% \item Use derivatives in approximation to solve illustrates how expectations ``smooth'' out the function ``kinks''
% \item time invariance and constraints on paths
% \item perturbation techniques on $x+{t-1}, \epsilon$
% \item $\epsilon$ could be any exogenous even time varying factor
% \item compute derivative of composition of function and use in update of decision rule from path errors
% \item add diagnostic tests to checkLinMod checkMod
% \item specify model definition requirements 
% \item exploit linearity get derivative for update
% \item generate a ``differential equation''
% \item makeDRFunc and reconcile assessment and update code
% \item use composition instead of stacking make interpolation decision rule pair
% \item way to use centered and backward sums of z's
% \item use derivative of sum and integral in update of function
% \item time invariance iteration constraints on z's and paths
% \item time invariance and function updates
% \item $z(x,\epsilon,y)$? just need y ``exogenous''  y discrete, continuous, stochastic
% \item progress monitor
% \item big shocks abort linear liftoff good cautionary example
% \item parallel
% \item smolyak
% \item constraint
% \item regime
% \item error messages
% \item lucamod big shock
% \item how to ``snug up'' solution using global feature of AMA series
% \item linearity of representation and updating
% \item deprecate path extension
% \item fact that are decision rule constrains z's How? z's are all part of a decision rule uniqueness topology
% \item one step defines all values  --  this should be exploitable
% \item decision rule differs slightly from conditional expetation that gets iterated shock puts you on a path
% \item mention possible to use Sims inputs
% \item continuous time
% \item $\Delta(x_{t-1},\epsilon_t) \implies \Delta Z(x_{t-1}) \implies PATH \implies NewZs$
% \item suspect there is a corresponding PDE that may be easy to solve numerically
% \item problem probably already solved in topology ( category theory )
% \item perhaps can approx the exact PDE by using just a few terms
% \item for time invariant map just need to get one step right so shouldn't need to worry about iterated compositions in formula for differential equaiton
% \item Euler residuals like Luca and other measures like Villaverde use maliar measures 
% \item findroot, nsolve other for deterministic problem
% \item use all equations ==
% \item nsolve choose multiple --  more constraints
% \item \href{mathematica nsolve info}{http://mathematica.stackexchange.com/questions/47112/what-algorithms-does-nsolve-use}
% \item \href{some choices}{http://mathematica.stackexchange.com/questions/40543/methods-for-nsolve}
%   \begin{itemize}
%   \item "EndomorphismMatrix"
% "CompanionMatrix"
% \item 
% "Legacy"
% \item 
% "Aberth"
% \item 
% "JenkinsTraub"
%   \end{itemize}
% \item do maliar exercises
% \item do rubio exercises
% \item do luca exercises
% \item equations CompiledFunction if findroot
% \item equations Function if NSolve
% \item java minimizer with constraints 
% \item $dr1 = \sum ... z_1, dr2 = \sum ... z_2,,, dr2 - dr1= \sum ... (z_2-z_1)$
% \item $dr_\ast - dr1= \sum ... (z_\ast-z_1)$
% \item warnings about extrapolation
% \item generate PDE
% \item time invariance constraints on zs 
% \item $ \Delta z \implies \Delta z \implies \Delta path$
% \item implement derivative
% \item functions with through can likely be parallelized also maps
% \item kernel fireup time?
% \item behavior when multiple solutions and when no solutions
% \item how best to associate eqnFuncs with lilxkzkfunc 
% \item multistep iterateions should match steady state solution exactly (see 
% AMASeriesRepresentationExamples notebook for developing derivatives
% \item should develop a test suite demonstrating identities satisfied
% \item update path using newton step,  Stack` $\frac{\partial Z()}{\partial x_{t-1}}$
% \item verify chunks can have t-1 and t  values
% \item solve closed form example in one verifying iteration
% \item ``pruned'' perturbation solution for initial guess at cond exp
% \item can use to assess ``pruned'' perturbation solution
% \item just collocation could be projection
% \item make sure multiple shocks okay; implementation versus theoretical constraint
% \item  could use different linmods for each regime
% \item inits for nsolve, handholding for nsolve
% \item improve monitors for misapplied functions
% \item nsolve about 500 times a long as findroot
% \item any time invariant dr with bounded solutions can be written as a series proof by construction
% \end{itemize}
% `	
% \newpage
% \appendix

% \section{Arbitrary Path Generator Programs}
% \label{sec:arbitr-path-gener}

% \listinginput{1}{arbGenPath.mth}

% \section{Program Signatures}
% \label{sec:program-listings}
% \begin{tabular}{|l|c|}
% \hline
% Number of $x_t$ variables&$\numX$\\
% \hline
% Number of $z_t$ variables&$\numZ$\\
% \hline
% Number of $\epsilon_t$ variables&$\numEps$\\
% \hline
% Number of regimes variables&$\numR$\\
% \hline
% Number of recursive iterations&$\numIters$\\
% \hline
% Interpolation Grid Specification&$\dstSpec$\\
% \hline
% Shock Distributions  Specification&$\dstSpec$\\
% \hline
% The Linear Reference Model&$\linMod\equiv\linModMats$\\  
% \hline
% Model Equation Function&$\eqnFuncSig$\\
% \hline
% \end{tabular}
% \subsection{genLilXkZkFunc}
% \label{sec:genlilxkzkfunc}
% \begin{gather*}
% \linMod \times \{  \bigXFuncSig, k \} \times \Rn{(\numX+\numEps)} \rightarrow
% huh%\lilXFuncSig
% \end{gather*}

% \subsection{genFRFunc,genNSFunc}
% \label{sec:genfrfunc}


% \begin{gather*}
% \{\numX,\numEps,\numZ\}\times(\lilXFuncSig)\times (\eqnFuncSig)    \rightarrow\\
% \frfpnsFuncSig
% \end{gather*}



% \subsection{genFPFunc}
% \label{sec:genfpfunc}
% \begin{gather*}
% \linMod \times \{  \bigXFuncSig, k \} \times (\eqnFuncSig)    \rightarrow\\ 
% \frfpnsFuncSig
% \end{gather*}




% \subsection{genXZREInterpFunc}
% \label{sec:genfpfunc}
% \begin{gather*}
% \{\numX,\numEps,\numZ\}\times(\lilXFuncSig)\times \grdSpec \times  \dstSpec   \rightarrow\\
% \bigXFuncSig
% \end{gather*}



% \subsection{doIterREInterp}
% \label{sec:doiterreinterp}

% \begin{gather*}
%   \linMod \times 
% w\{(\lilXFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnFuncSig ) \times \grdSpec \times \dstSpec \rightarrow\\
% \{\frfpnsFuncSig, \{(\lilXFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}\}
% \end{gather*}



% \subsection{nestIterREInterp}
% \label{sec:nestiterreinterp}



% \begin{gather*}
%   \linMod \times 
% \{(\lilXFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnFuncSig ) \times \grdSpec \times \dstSpec \times \numIters \rightarrow\\
% \{\frfpnsFuncSig, \{(\lilXFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}\}
% \end{gather*}



% \subsection{genLilXkZkRegimeFuncs}
% \label{sec:genlilxkzkregimefunc}
% {\small
% \begin{gather*}
% \linMod \times \{(\{  \bigXFuncSig, k_i \})_{k_i=1},\ldots,(\{  \bigXFuncSig, k_i \})_{k_i=\numR}\} \times\\ \Rn{(\numX+\numEps)} \rightarrow\\
% \{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}
% \end{gather*}
% }





% \subsection{genFRRegimeFuncs, genNSRegimeFuncs}
% \label{sec:genfrregimefunc}



% {\small
% \begin{gather*}
% \{\numX,\numEps,\numZ\}\times\\
% \{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnRegimeFuncSig )\rightarrow\\
% \frfpnsRegimeFuncSig
% \end{gather*}
% }








% \subsection{genFPRegimeFuncs}
% \label{sec:genfpregimefunc}




% {\small
% \begin{gather*}
% \{\numX,\numEps,\numZ\}\times\\
% \{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnRegimeFuncSig )\rightarrow\\
% \frfpnsRegimeFuncSig
% \end{gather*}
% }




% \subsection{genXZREInterpRegimeFuncs}
% \label{sec:genfpfunc}
% \begin{gather*}
% \{\numX,\numEps,\numZ\}\times(\lilXFuncSig)\times \dstSpec \times  \expctSpec   \rightarrow\\
% \frfpnsFuncSig
% \end{gather*}



% \subsection{doIterREInterpRegime}
% \label{sec:doiterreinterp}

% \begin{gather*}
%   \linMod \times 
% w\{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnRegimeFuncSig ) \times \grdSpec \times \dstSpec \rightarrow\\
% \{\frfpnsRegimeFuncSig, \{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}\}
% \end{gather*}



% \subsection{nestIterREInterpRegime}
% \label{sec:nestiterreinterp}



% \begin{gather*}
%   \linMod \times 
% w\{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}  \\
%  \times (\eqnRegimeFuncSig ) \times \grdSpec \times \dstSpec  \times \numIters \rightarrow\\
% \{\frfpnsRegimeFuncSig, \{(\lilXRegimeFuncSig)_1,\ldots,(\lilXFuncSig)_{\numR}\}\}
% \end{gather*}


\appendix

\section{Support Vector Machines}
\label{sec:supp-vect-mach}


\subsection{Univariate Function Approximation}


Consider models of the form 
\begin{gather}
y=f(x)+ \epsilon_t\\
f(x)= \sum_{i=1}^L\theta_ik(x_i,x)+b
\end{gather}
where $k(x_i,x)$ is some kernel that can be written as a dot product.\cite{hofmann06kernelreview}.  This ``kernel trick'' provides a very flexible array of
functional forms for fitting the data.
We minimize a loss function of the form
\begin{gather}
L=\frac{1}{2}||w||^2 + C \sum_{i=1}^L (\xi_i+\xi_i^\ast) - \sum_{i=1}^L (\eta_i\xi_i+\eta_i^\ast \xi_i^\ast) -\\
\sum_{i=1}^L \alpha_i(\epsilon_i +\xi_i - y_i + k(x_i,x) +b)- \nonumber\\
\sum_{i=1}^L \alpha_i^\ast(\epsilon_i +\xi_i^\ast + y_i - k(x_i,x) -b)\nonumber
\end{gather}

As a result, analagous to a  hinge loss function, 
errors near the predicted value are ``costless'' while those further away
impact cost in proportion to their linear distance from the prediction.

I have written a set of Mathematica functions that 
construct and solve the related quadratic programming problem.
The code is written to be easily extendable.
I have implemented several widely used kernels including dot product, 
polynomial, radial basis function.
described widely in the literature.\cite{palancz05:suppor,smola2004tutorial,Alpaydin2004}. In addition there are important implementation insights in\cite{platt98sequential}


\subsection{Multivariate Function Approximation}

\href{https://scholar.google.com/scholar?oe=utf-8&um=1&ie=UTF-8&lr&cites=11562147006083824949}{citations of \cite{conf/icann/Perez-CruzCSPFA02}}
\href{http://library.wolfram.com/infocenter/Conferences/7006/}{mathematica recurrent neural net 2007}

\href{http://community.wolfram.com/groups/-/m/t/824280}{mma neural net}
 \bibliographystyle{plainnat}
 \bibliography{../../bibFiles/anderson,../../bibFiles/files}

\end{document}


