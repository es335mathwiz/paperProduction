\documentclass[12pt]{article}
\title{Using Support Vector Machine Function Approximation to
Mitigate the Curse of Dimensionality in Model with Occasionally Binding Constraints}
\author{Gary S. Anderson}
\begin{document}
\begin{abstract}
Support vector machines occupy a prominent place applied machine learning
Additionally they can reduce the burden of computation as they determine 
a subset of points that are important in characterizing a given function.
Kernel trick,  powerful representation quadratic programming solution to compute there are on-line techniques for adding and deleting individual points from the representation.  A weighted sum of kernel functions RBF, wavelet, special forms for time series.
  This paper proposes a new series representation for bounded so-
lutions to dynamic models. This series representation can be used
to determine a series representation for time invariant discrete time
maps that characterize the solutions to many models. Consequently,
the technique constitutes an important component in a technique for
accurately characterizing the solutions for a wide array of nonlinear
rational expectations models. It can also provide a formula for com-
puting accuracy bounds for any proposed time invariant model so-
lution. The series representation serves as an important component
in an algorithm for constructing approximate solutions for nonlinear
rational expectations models.
The technique recursively computes solutions that honor the con-
straints for successively longer horizons. The technique also provides
a metric for determining apriori how long the horizon must be for a
given level of accuracy of the state vector. The solutions computed by
the technique accommodate the possibility that model trajectories can
depart from and re-engage inequality constraints as well as transition
between various regimes.
\end{abstract}
\end{document}
